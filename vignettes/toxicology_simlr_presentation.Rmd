---
title: "PCA, CCA and SiMLR: simple examples and nhanes application"
author: "Brian B. Avants"
date: "2/5/2025"
output: html_document
---



	•	Ellipse: Represents the data spread based on its covariance structure.
	•	Principal Component Vectors:
	•	Solid black arrow for PC1 (explains the most variance).
	•	Dashed black arrow for PC2 (orthogonal to PC1).

This gives an intuitive visualization of PCA in action.

```{r pca}
# Load necessary libraries
library(ggplot2)
library(ggfortify)
library(ellipse)
library(ANTsR)
library(subtyper)

# Generate sample data
set.seed(42)
data <- matrix(rnorm(200), ncol = 2)
data <- data %*% matrix(c(1, 0.4, 0.6, 1), ncol = 2)  # Introduce correlation
df <- as.data.frame(data)
colnames(df) <- c("Feature1", "Feature2")

# Perform PCA
pca_result <- prcomp(df, center = TRUE, scale. = TRUE)

# Get mean of the data
center_x <- mean(df$Feature1)
center_y <- mean(df$Feature2)

# Get principal component vectors (scaled for visualization)
pc1 <- pca_result$rotation[,1] * sqrt(pca_result$sdev[1]) * 2
pc2 <- pca_result$rotation[,2] * sqrt(pca_result$sdev[2]) * 2

# Generate ellipse to fit the data
ellipse_data <- as.data.frame(ellipse(cov(df), centre = colMeans(df)))
colnames(ellipse_data) <- c("Feature1", "Feature2")  # Rename for ggplot compatibility

# Plot PCA results with ellipse and principal component vectors
ggplot(df, aes(x = Feature1, y = Feature2)) +
  geom_point(color = 'blue', alpha = 0.6) +  # Scatter plot of data
  geom_path(data = ellipse_data, aes(x = Feature1, y = Feature2), color = 'red', linewidth = 1) +  # Elliptical fit
  annotate("segment", x = center_x, y = center_y, 
           xend = center_x + pc1[1], yend = center_y + pc1[2], 
           arrow = arrow(length = unit(0.2, "cm")), color = "black", linewidth = 1.2) +  # PC1
  annotate("segment", x = center_x, y = center_y, 
           xend = center_x + pc2[1], yend = center_y + pc2[2], 
           arrow = arrow(length = unit(0.2, "cm")), color = "black", linewidth = 1.2, linetype = "dashed") +  # PC2
  ggtitle("PCA with Elliptical Fit and Principal Component Axes") +
  theme_minimal()
```




This version first plots the original data (X1, X2 vs. Y1, Y2) and then displays the transformed low-dimensional projections (U1 vs. V1 from CCA).

```{r cca,fig.width=10,fig.height=4}

# Load necessary libraries
library(ggplot2)
library(gridExtra)
library(ellipse)

# Set seed for reproducibility
set.seed(42)

# Generate X (two independent variables)
X <- matrix(rnorm(200), ncol = 2)

# Generate Y with weaker dependence on X
Y <- X %*% matrix(c(0.3, 0.1, 0.1, 0.3), ncol = 2) + matrix(rnorm(200, sd = 0.8), ncol = 2)

# Convert to data frames
df_X <- as.data.frame(X)
df_Y <- as.data.frame(Y)
colnames(df_X) <- c("X1", "X2")
colnames(df_Y) <- c("Y1", "Y2")

# Perform Canonical Correlation Analysis (CCA)
cca_result <- cancor(df_X, df_Y)

# Compute the first canonical variates
U1 <- as.matrix(df_X) %*% cca_result$xcoef[,1]  # First canonical variate for X
V1 <- as.matrix(df_Y) %*% cca_result$ycoef[,1]  # First canonical variate for Y

# Create a dataframe for plotting
cca_data <- data.frame(U1 = U1, V1 = V1)

# Get centers
center_x <- mean(cca_data$U1)
center_y <- mean(cca_data$V1)

# Compute canonical correlation axes
cca_axis1_x <- cca_result$xcoef[,1] * 2
cca_axis1_y <- cca_result$ycoef[,1] * 2

# Generate ellipse for canonical variates
ellipse_data <- as.data.frame(ellipse(cov(cca_data), centre = colMeans(cca_data)))
colnames(ellipse_data) <- c("U1", "V1")

# Original Data Plot
p1 <- ggplot() +
  geom_point(data = df_X, aes(x = X1, y = X2), color = 'blue', alpha = 0.6) +
  geom_point(data = df_Y, aes(x = Y1, y = Y2), color = 'red', alpha = 0.6) +
  ggtitle("Original Data (X and Y)") +
  theme_minimal()

# CCA Projection Plot
p2 <- ggplot(cca_data, aes(x = U1, y = V1)) +
  geom_point(color = 'blue', alpha = 0.6) +  # Scatter plot of canonical variates
  geom_path(data = ellipse_data, aes(x = U1, y = V1), color = 'red', linewidth = 1) +  # Elliptical fit
  annotate("segment", x = center_x, y = center_y, 
           xend = center_x + cca_axis1_x[1], yend = center_y + cca_axis1_y[1], 
           arrow = arrow(length = unit(0.2, "cm")), color = "black", linewidth = 1.2) +  # First canonical axis
  annotate("segment", x = center_x, y = center_y, 
           xend = center_x + cca_axis1_x[2], yend = center_y + cca_axis1_y[2], 
           arrow = arrow(length = unit(0.2, "cm")), color = "black", linewidth = 1.2, linetype = "dashed") +  # Second canonical axis
  ggtitle("CCA Projection (U1 vs V1) - Moderate Correlation") +
  theme_minimal()

# Arrange plots side by side
grid.arrange(p1, p2, ncol = 2)

```



now three views


```{r simlrsetup,fig.width=12,fig.height=6}

generate_Y <- function(X, mync, nz ) {
  # Ensure that X is a matrix with at least 3 columns
  if (ncol(X) < 3) {
    stop("X must have at least 3 columns.")
  }

  # Generate initial noise matrix for Y (with the same number of columns as X)
  noise_matrix <- matrix(rnorm(nrow(X) * ncol(X), sd = nz[1]), ncol = ncol(X))
  
  # Create Y by adding noise to X
  Y <- X + noise_matrix

  # Add additional noise to reach the target number of columns (mync)
  additional_noise <- matrix(rnorm(nrow(X) * (mync - ncol(X)), sd = nz[2]), ncol = (mync - ncol(X)))

  # Combine to get the final Y matrix with the desired number of columns
  Y_final <- cbind(Y, additional_noise)

  # Return the final Y matrix
  return(Y_final)
}


matrix_from_latent <- function(latent_matrix, target_p, noise_sd = 0.3) {
  # Get dimensions of latent matrix
  n <- nrow(latent_matrix)
  k <- ncol(latent_matrix)
  
  # Generate a random transformation matrix (k x target_p)
  transformation_matrix <- matrix(rnorm(k * target_p), nrow = k, ncol = target_p)
  
  # Generate the new matrix by multiplying latent matrix with transformation and adding noise
  new_matrix <- latent_matrix %*% transformation_matrix + 
                matrix(rnorm(n * target_p, sd = noise_sd), nrow = n, ncol = target_p)
  
  return(new_matrix)
}


# Load necessary libraries
library(ggplot2)
library(gridExtra)
library(geigen)

# Set seed for reproducibility
set.seed(42)

nzsd=0.5
mync=c(2,225,350,1070)
mynz=c(0.1,0.2,0.3)
# Generate X (three independent variables)
latent <- matrix(rnorm(300, sd=0.25 ), ncol = mync[1])

X = matrix_from_latent( latent, mync[2], mynz[1] )
Y = matrix_from_latent( latent, mync[3], mynz[2] )
Z = matrix_from_latent( latent, mync[4], mynz[3] )


# Convert to data frames
df_X <- as.data.frame(X)
df_Y <- as.data.frame(Y)
df_Z <- as.data.frame(Z)
colnames(df_X) <- paste0("X",1:ncol(X))
colnames(df_Y) <-  paste0("Y",1:ncol(Y))
colnames(df_Z) <-  paste0("Z",1:ncol(Z))
```


```{r simlr0,fig.width=12,fig.height=6}
# --- GCCA Computation ---
data_list <- list(as.matrix(df_X), as.matrix(df_Y), as.matrix(df_Z))

# Compute covariance matrices
cov_matrices <- lapply(data_list, cov)
inv_cov_matrices <- lapply(cov_matrices, function(C) solve(C + diag(1e-4, ncol(C))))  # Regularization


regs <- regularizeSimlr(data_list,fraction=0.15,sigma=rep(1.0,3))
initu=initializeSimlr( data_list, k=20 )
if ( ! exists( "result2" ) ) {
    result2 <- simlr(data_list,regs, iterations=100, 
        sparsenessQuantiles=rep(0.5,length(data_list)),
        positivities=rep("positive",length(data_list)), 
        energyType='regression',
        mixAlg='ica',
        initialUMatrix=initu, verbose=T)
    }
pred2 <- predictSimlr(data_list, result2)
U_X <- data_list[[1]] %*% (result2$v[[1]])
U_Y <- data_list[[2]] %*% (result2$v[[2]])
U_Z <- data_list[[3]] %*% (result2$v[[3]])
   
if ( FALSE ) {
# Compute GCCA cross-covariance matrix
G <- Reduce("+", lapply(1:length(data_list), function(i) {
  Reduce("+", lapply(1:length(data_list), function(j) {
    print(paste(i," ",j))
    if (i != j) {
      inv_cov_matrices[[i]] %*% cov(data_list[[i]], data_list[[j]]) %*% inv_cov_matrices[[j]]
    } else {
      matrix(0, ncol = ncol(data_list[[i]]), nrow = ncol(data_list[[j]]))
    }
  }))
}))

# Solve generalized eigenproblem
eig_result <- geigen(G, diag(ncol(G))) 
proj_vectors <- eig_result$vectors[, 1:2]  # First two GCCA components

# Compute GCCA projections
U_X <- as.matrix(df_X) %*% proj_vectors
U_Y <- as.matrix(df_Y) %*% proj_vectors
U_Z <- as.matrix(df_Z) %*% proj_vectors
}
# Create a dataframe for visualization
gcca_data <- data.frame(U1 = U_X[,1], U2 = U_X[,2], 
                        V1 = U_Y[,1], V2 = U_Y[,2], 
                        W1 = U_Z[,1], W2 = U_Z[,2])

```

```{r simlr1,fig.width=12,fig.height=6}
# --- Pairwise GCCA Projection Plots ---
# X vs Y
p_XY <- ggplot(gcca_data, aes(x = U1, y = V1)) +
  geom_point(color = 'purple', alpha = 0.6) +
  ggtitle("SiMLR Projection: X vs Y") +
geom_smooth(method = "lm", color = "blue", linetype = "dashed", se = FALSE) +    theme_minimal()

# X vs Z
p_XZ <- ggplot(gcca_data, aes(x = U1, y = W1)) +
  geom_point(color = 'orange', alpha = 0.6) +
  ggtitle("SiMLR Projection: X vs Z") +
geom_smooth(method = "lm", color = "blue", linetype = "dashed", se = FALSE) +    theme_minimal()

# Y vs Z
p_YZ <- ggplot(gcca_data, aes(x = V1, y = W1)) +
  geom_point(color = 'green', alpha = 0.6) +
  ggtitle("SiMLR Projection: Y vs Z") +
geom_smooth(method = "lm", color = "blue", linetype = "dashed", se = FALSE) +  theme_minimal()

# --- Original Data Plots ---
# X Data
p_X <- ggplot(df_X, aes(x = X1, y = X2)) +
  geom_point(color = 'blue', alpha = 0.6) +
  ggtitle("Original X Data") +
  theme_minimal()

# Y Data
p_Y <- ggplot(df_Y, aes(x = Y1, y = Y2)) +
  geom_point(color = 'red', alpha = 0.6) +
  ggtitle("Original Y Data") +
  theme_minimal()

# Z Data
p_Z <- ggplot(df_Z, aes(x = Z1, y = Z2)) +
  geom_point(color = 'green', alpha = 0.6) +
  ggtitle("Original Z Data") +  theme_minimal()

# Arrange the plots: GCCA and Original Data
grid.arrange(p_X, p_Y, p_Z, p_XY, p_XZ, p_YZ, ncol = 3)

```


## NHANES example


```{r nhanes}

impute_and_report_na <- function(mat) {
  # Ensure input is a matrix
  if (!is.matrix(mat)) {
    stop("Input must be a matrix.")
  }
  
  # Get column names
  col_names <- colnames(mat)
  
  # Initialize a report list
  na_report <- list()
  
  # Iterate over columns
  for (i in seq_along(col_names)) {
    col_data <- mat[, i]
    na_count <- sum(is.na(col_data))
    
    if (na_count > 0) {
      # Impute missing values with column mean
      col_mean <- mean(col_data, na.rm = TRUE)
      col_data[is.na(col_data)] <- col_mean
      
      # Store NA report
      na_report[[col_names[i]]] <- na_count
    }
    
    # Replace column in matrix
    mat[, i] <- col_data
  }
  
  # Print NA report
  if (length(na_report) > 0) {
    cat("NA counts per column:\n")
    print(na_report)
  } else {
    cat("No missing values detected.\n")
  }
  
  return(mat)
}

convert_to_numeric_matrix <- function(df) {
  # Load necessary package
  if (!requireNamespace("fastDummies", quietly = TRUE)) {
    install.packages("fastDummies")
  }
  library(fastDummies)
  
  # Identify categorical and numeric columns
  cat_cols <- sapply(df, is.character) | sapply(df, is.factor)
  num_cols <- !cat_cols
  
  # If all columns are numeric, return the original matrix
  if (all(num_cols)) {
    return(as.matrix(df))
  }
  
  # One-hot encode categorical columns
  if (any(cat_cols)) {
    df_cat <- fastDummies::dummy_cols(df[, cat_cols, drop = FALSE], 
                                      remove_first_dummy = FALSE, 
                                      remove_selected_columns = TRUE)
  } else {
    df_cat <- NULL
  }
  
  # Extract numeric columns
  df_num <- if (any(num_cols)) df[, num_cols, drop = FALSE] else NULL
  
  # Combine numeric and encoded categorical columns
  df_final <- cbind(df_num, df_cat)
  
  # Convert to matrix
  return(as.matrix(df_final))
}

count_unique_values <- function(df, threshold) {
  results <- logical(ncol(df))
  names(results) <- colnames(df)
  
  for (col_name in colnames(df)) {
    unique_count <- length(unique(df[[col_name]]))
    cat(col_name, ":", unique_count, "unique values\n")
    results[col_name] <- unique_count > threshold
  }
  
  return(df[,results])
}


read_and_filter_xpt <- function(file_path, threshold = 100) {
  df <- data.frame(read_xpt(file_path))
  colnames(df)[1] <- "ID"
  return( count_unique_values(df, threshold) )
}

impute_data <- function(df) {
  imputed_df <- df  # Copy input data
  
  for (col in names(df)) {
    if (is.numeric(df[[col]])) {
      # Impute numeric columns with median
      median_val <- median(df[[col]], na.rm = TRUE)
      imputed_df[[col]][is.na(imputed_df[[col]])] <- median_val
    } else {
      # Impute categorical columns with the most frequent category
      freq_table <- table(df[[col]], useNA = "no")
      most_frequent <- names(freq_table)[which.max(freq_table)]
      imputed_df[[col]][is.na(imputed_df[[col]])] <- most_frequent
    }
  }
  
  return(imputed_df)
}

library(NHANES)
library(haven)
nhan=data.frame( NHANES )
cog = read_and_filter_xpt( "CFQ_G_2011_2012.xpt", 25 )
cog2 = read_and_filter_xpt( "CFQ_H_2013_2014.xpt", 25 )
voc = read_and_filter_xpt( "VOCWB_G_2011_2012.xpt", 100 )
voc2 = read_and_filter_xpt( "VOCWB_G_2013_2014.xpt", 100 )
mtl = read_and_filter_xpt( "UHMS_G_2011_2012.xpt", 100 )
nhan=merge(nhan,cog,by='ID'); dim(nhan)
# nhan=merge(nhan,cog2,by='ID'); dim(nhan)
nhan=merge(nhan,voc,by='ID'); dim(nhan)
# nhan=merge(nhan,voc2,by='ID'); dim(nhan)
expnms = unique( c( colnames(voc)[-c(1:2)], colnames(voc2)[-c(1:2)] ) )
# nhan=merge(nhan,mtl,by='ID')
# expnms = colnames(mtl)[-c(1:2)]
# nhan=merge(nhan,mtl,by='ID'); dim(nhan)
# expnms = c( colnames(mtl)[-c(1:2)], colnames(voc)[-c(1:2)] )
#############################################################################
mdl = lm( CFDDS ~ Age + Gender  + Poverty + Education + MaritalStatus + BMI +
    LittleInterest + PhysActive, data=nhan )
summary( mdl )
mdl = lm( CFDAST ~ Age + Gender  + Poverty + Education + MaritalStatus + BMI +
    LittleInterest + PhysActive, data=nhan )
summary( mdl )
colcats=rep("Basic",ncol(nhan))
nhan$GenderM = 0
nhan$GenderM[nhan$Gender=='male'] = 1
colcats[ colnames(nhan) %in%  c("Age","GenderM") ]='demog'
colcats[ colnames(nhan) %in%  c("Education","Poverty") ]='background'
bpname=getNamesFromDataframe( "BP",nhan)
# colcats[ colnames(nhan) %in%  c("BMI","Heigh","Weight",bpname,"Testosterone","TotChol","Diabetes","HealthGen") ]='physical'
colcats[ colnames(nhan) %in%  c("BMI","Height","Weight",bpname,"Testosterone","TotChol","Diabetes" ) ]='physical'
# colcats[ colnames(nhan) %in%  c('LittleInterest','Depressed','SleepTrouble','PhysActive','PhysActiveDays','TVHrsDay') ]='mentalhealth'
colcats[ colnames(nhan) %in%  c('LittleInterest','Depressed','SleepTrouble','PhysActive','PhysActiveDays') ]='mentalhealth'
colcats[ colnames(nhan) %in%  c('CFDDS') ]='digitspan'
colcats[ colnames(nhan) %in%  expnms ]='exposures'
# table(colcats)

nh_list=list()
knm=c("background","demog","mentalhealth","physical",'exposures')
for ( k in knm ) {
    print(k)
    temp0=impute_data(nhan[,colcats==k])
    temp = data.frame(convert_to_numeric_matrix( temp0 ))
    for ( j in 1:ncol(temp) ) {
        hist( temp[,j], main=colnames(temp)[j])
#        Sys.sleep(1)
        }
    nh_list[[length(nh_list)+1]]=data.matrix( impute_data( temp ) )
#    nh_list[[length(nh_list)]]=impute_and_report_na(nh_list[[length(nh_list)]] )
    }
names(nh_list)=knm
#####
```



```{r nhanessimlr}
regs <- regularizeSimlr(nh_list,fraction=0.15,sigma=rep(1.0,length(nh_list)))
regs <- regularizeSimlr(nh_list)
regs[[2]]=diag(2)
initu=initializeSimlr( nh_list, k=40, jointReduction=TRUE )
resultNH <- simlr(nh_list, iterations=100, 
        sparsenessQuantiles=rep(0.5,length(nh_list)),
        positivities=rep("positive",length(nh_list)), 
        energyType='regression', mixAlg='ica',
#        energyType='cca', mixAlg='pca',
#        scale=c("centerAndScale", "np"),
        scale=c( "robust", "centerAndScale", "np" ),
        constraint="Stiefelx1000x1000",
        initialUMatrix=initu, verbose=T)
###############
projlist=list()
mysimk=2
for ( k in 1:length(nh_list)) {
    rownames(resultNH$v[[k]])=colnames( nh_list[[k]])
    ux=data.frame(nh_list[[k]] %*% abs(resultNH$v[[k]][,1:mysimk]))
    colnames(ux)=paste0(names(nh_list)[k],1:ncol(ux))
    projlist[[length(projlist)+1]]=ux
}
simdf=simdf2=dplyr::bind_cols(projlist)
simdf2$CFDDS=nhan$CFDDS
simdf2$CFDAST=nhan$CFDAST
myform = paste0( "CFDDS ~ ",paste0( colnames(simdf), collapse='+'))
mdl = lm( myform, data=simdf2 )
print( summary( mdl ) )
#######################
interpret_simlr_vector2( resultNH$v[['exposures']], 1, n2show=5, shortnames=F )
interpret_simlr_vector2( resultNH$v[['exposures']], 2, n2show=5, shortnames=F )
# https://wwwn.cdc.gov/nchs/nhanes/search/default.aspx
# > interpret_simlr_vector2( resultNH$v[['exposures']], 1, n2show=5, shortnames=F )
#   LBXVBZ    LBXVOX    LBXVFN    LBX2DF 
# benzene, Xylene, furan, Dimethylfuran
# 1.0000000 0.3346728 0.1868323 0.0586727 
#######################
###
```
